name: CI for Spark Project

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install Python dependencies and PySpark
        run: |
          pip install -r requirements.txt

      - name: List installed Python packages
        run: |
          pip list

      - name: Set up Java
        uses: actions/setup-java@v2
        with:
          java-version: '11'
          distribution: 'adopt'

      - name: Set up Apache Spark
        run: |
          wget -qO- "https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz" | tar -xz -C /tmp/
          echo "SPARK_HOME=/tmp/spark-3.1.1-bin-hadoop2.7" >> $GITHUB_ENV
          echo "$SPARK_HOME/bin" >> $GITHUB_PATH

      - name: Test PySpark Setup
        run: |
          python -c "from pyspark.sql import SparkSession; spark = SparkSession.builder.master('local[2]').appName('TestPySpark').getOrCreate(); print(spark.version); spark.stop()"

      - name: Run main.py (optional for CI)
        env:
          PYTHONPATH: ${{ github.workspace }}/src
          CI: true # Ensuring main.py recognizes it's running in a CI environment
        run: |
          python src/main.py

      - name: Run PySpark tests
        env:
          PYTHONPATH: ${{ github.workspace }}/src
        run: |
          pytest tests/
